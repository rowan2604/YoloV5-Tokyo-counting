{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615dae68",
   "metadata": {},
   "source": [
    "## exemple test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa99ca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\rowan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-7 Python-3.8.11 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(\"tvid.mp4\")\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "b=model.names[2] = 'car'\n",
    "c=model.names[0] = 'person'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7458339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "size=416\n",
    "\n",
    "count=0\n",
    "counter=0\n",
    "\n",
    "\n",
    "color=(0,0,255)\n",
    "cx1=600\n",
    "cy1=300\n",
    "offset=6\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "\n",
    "    count += 1\n",
    "    if count % 4 != 0:\n",
    "         continue\n",
    "    img=cv2.resize(img,(600,500)) #prendre pourcentage des pixels taille de l'écran 960,540\n",
    "    cv2.line(img,(79,cy1),(599,cy1),(0,0,255),2)\n",
    "    results=model(img,size)\n",
    "    a=results.pandas().xyxy[0]\n",
    "    #print(a)\n",
    "\n",
    "    for index, row in results.pandas().xyxy[0].iterrows():\n",
    "        \n",
    "        x1=int(row['xmin'])\n",
    "        y1=int(row['ymin'])\n",
    "        x2=int(row['xmax'])\n",
    "        y2=int(row['ymax'])\n",
    "        \n",
    "        x_dist=x2-x1\n",
    "        y_dist=y2-y1\n",
    "        sum_dist=x_dist+y_dist\n",
    "        \n",
    "        d=(row['class'])\n",
    "        conf=(row['confidence'])\n",
    "        \n",
    "        if d==2:\n",
    "            #print(\"x_dist+ \",x_dist,\"y_dist+ \",y_dist,\"sum\",sum_dist)\n",
    "            #if sum_dist>140:\n",
    "                if conf>0.4 :\n",
    "                    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "                    rectcenter=int(rectx1),int(recty1)\n",
    "                    cx=rectcenter[0]\n",
    "                    cy=rectcenter[1]\n",
    "                    cv2.circle(img,(cx,cy),2,(255,0,0),-1)\n",
    "                    #cv2.putText(img,str(conf),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                #if cy<(cy1+offset) and cy>(cy1-offset):\n",
    "                if cy<(cy1+offset) and cy>(cy1-offset):\n",
    "                    counter+=1\n",
    "                    cv2.line(img,(79,cy1),(599,cy1),(0,255,0),2)\n",
    "                    #cv2.line(img,(200,cy1),(400,cy1),(0,255,127),2)\n",
    "                    print(counter)\n",
    "                cv2.putText(img,str(counter),(x2,y2),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "        if d==0:\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "            rectcenter=int(rectx1),int(recty1)\n",
    "            cx=rectcenter[0]\n",
    "            cy=rectcenter[1]\n",
    "            cv2.circle(img,(cx,cy),3,(255,0,0),-1)\n",
    "            #cv2.putText(img,str(c),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,0),2)\n",
    "    cv2.imshow(\"exemple\",img)\n",
    "    if cv2.waitKey(30) &0xFF==27: #== ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5752a347",
   "metadata": {},
   "source": [
    "## test philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90564955",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\rowan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-7 Python-3.8.11 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(\"philadelphia.mp4\")\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "pool = ThreadPoolExecutor(max_workers=2)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "b=model.names[2] = 'car'\n",
    "c=model.names[0] = 'person'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2e2254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "size=416\n",
    "\n",
    "count=0\n",
    "counter=0\n",
    "\n",
    "\n",
    "color=(0,0,255)\n",
    "cx1=420\n",
    "cy1=580\n",
    "x_offset=6\n",
    "y_offset=6\n",
    "tab=[]\n",
    "\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "    batch = [cap.read()[1] for _ in range(2)]\n",
    "    if  not (batch):\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 4 != 0:\n",
    "         continue\n",
    "    img=cv2.resize(img,(900,600)) #prendre pourcentage des pixels taille de l'écran 960,540\n",
    "    cv2.line(img,(cx1,cy1),(cx1,cy1-100),(0,0,255),2)\n",
    "\n",
    "    results=model(img,size)\n",
    "    a=results.pandas().xyxy[0]\n",
    "    #print(a)\n",
    "\n",
    "    for index, row in results.pandas().xyxy[0].iterrows():\n",
    "        \n",
    "        x1=int(row['xmin'])\n",
    "        y1=int(row['ymin'])\n",
    "        x2=int(row['xmax'])\n",
    "        y2=int(row['ymax'])\n",
    "        \n",
    "        x_dist=x2-x1\n",
    "        y_dist=y2-y1\n",
    "        sum_dist=x_dist+y_dist\n",
    "        \n",
    "        d=(row['class'])\n",
    "        conf=(row['confidence'])\n",
    "        \n",
    "        if d==2:\n",
    "            #print(\"x_dist+ \",x_dist,\"y_dist+ \",y_dist,\"sum\",sum_dist)\n",
    "            #if sum_dist>140: #filtrer les rectangles inutiles\n",
    "                if conf>0.3 :\n",
    "                    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    tab.append(cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2))#\"puis afficher a chaque frame\"\n",
    "                    rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "                    rectcenter=int(rectx1),int(recty1)\n",
    "                    cx=rectcenter[0]\n",
    "                    cy=rectcenter[1]\n",
    "                    cv2.circle(img,(cx,cy),2,(255,0,0),-1)\n",
    "                    #cv2.putText(img,str(conf),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                #if cy<(cy1+offset) and cy>(cy1-offset) and cx<(cx1+offset) and cx>(cx1-offset):\n",
    "                if cx<(cx1+x_offset) and cx>(cx1-x_offset) and cy<(cy1+y_offset):\n",
    "                    counter+=1\n",
    "                    cv2.line(img,(cx1,cy1),(cx1,cy1-100),(0,255,0),3)\n",
    "                    #cv2.line(img,(200,cy1),(400,cy1),(0,255,127),2)\n",
    "                    print(counter)\n",
    "                    #cv2.putText(img,str(counter),(x2,y2),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "        if d==0:\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "            rectcenter=int(rectx1),int(recty1)\n",
    "            cx=rectcenter[0]\n",
    "            cy=rectcenter[1]\n",
    "            cv2.circle(img,(cx,cy),3,(255,0,0),-1)\n",
    "            #cv2.putText(img,str(c),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,0),2)\n",
    "    cv2.imshow(\"philadelphia\",img)\n",
    "    if cv2.waitKey(1) == ord('q'): #echap sortir\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11122c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "    img=cv2.resize(img,(900,600))\n",
    "    results=model(img,size)\n",
    "    a=results.pandas().xyxy[0]\n",
    "    #print(a)\n",
    "\n",
    "    for index, row in results.pandas().xyxy[0].iterrows():\n",
    "        cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "    #img=cv2.resize(img,(900,600)) #prendre pourcentage des pixels taille de l'écran 960,540\n",
    "    #cv2.imshow(\"philadelphia\",tab)\n",
    "        cv2.imshow(\"t\",img)\n",
    "    if cv2.waitKey(1) == ord('q'): #echap sortir\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f13615",
   "metadata": {},
   "source": [
    "### Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01ac2dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\rowan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-7 Python-3.8.11 torch-1.13.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(\"tokyo.mp4\")\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "b=model.names[2] = 'car'\n",
    "c=model.names[0] = 'person'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac640d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "size=416\n",
    "\n",
    "count=0\n",
    "counter=0\n",
    "\n",
    "\n",
    "color=(0,0,255)\n",
    "cx1=300\n",
    "cy1=450\n",
    "x_offset=6\n",
    "y_offset=6\n",
    "while True:\n",
    "    ret,img=cap.read()\n",
    "\n",
    "    count += 1\n",
    "    if count % 4 != 0:\n",
    "         continue\n",
    "    img=cv2.resize(img,(900,600)) #prendre pourcentage des pixels taille de l'écran 960,540\n",
    "    cv2.line(img,(cx1-100,cy1),(cx1,cy1-20),(0,0,255),2)\n",
    "\n",
    "    results=model(img,size)\n",
    "    a=results.pandas().xyxy[0]\n",
    "    #print(a)\n",
    "\n",
    "    for index, row in results.pandas().xyxy[0].iterrows():\n",
    "        \n",
    "        x1=int(row['xmin'])\n",
    "        y1=int(row['ymin'])\n",
    "        x2=int(row['xmax'])\n",
    "        y2=int(row['ymax'])\n",
    "        \n",
    "        x_dist=x2-x1\n",
    "        y_dist=y2-y1\n",
    "        sum_dist=x_dist+y_dist\n",
    "        \n",
    "        d=(row['class'])\n",
    "        conf=(row['confidence'])\n",
    "        \n",
    "        if d==2:\n",
    "            #print(\"x_dist+ \",x_dist,\"y_dist+ \",y_dist,\"sum\",sum_dist)\n",
    "            if sum_dist>140: #filtrer les rectangles inutiles\n",
    "                if conf>0.4 :\n",
    "                    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "                    rectcenter=int(rectx1),int(recty1)\n",
    "                    cx=rectcenter[0]\n",
    "                    cy=rectcenter[1]\n",
    "                    cv2.circle(img,(cx,cy),2,(255,0,0),-1)\n",
    "                    #cv2.putText(img,str(conf),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "                #if cy<(cy1+offset) and cy>(cy1-offset) and cx<(cx1+offset) and cx>(cx1-offset):\n",
    "                if cx<(cx1+x_offset) and cx>(cx1-x_offset) and cy<(cy1+y_offset):\n",
    "                    counter+=1\n",
    "                    cv2.line(img,(cx1-100,cy1),(cx1,cy1-20),(0,255,0),3)\n",
    "                    print(counter)\n",
    "                    #cv2.putText(img,str(counter),(x2,y2),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255),2)\n",
    "        if d==0:\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            rectx1,recty1=((x1+x2)/2,(y1+y2)/2)\n",
    "            rectcenter=int(rectx1),int(recty1)\n",
    "            cx=rectcenter[0]\n",
    "            cy=rectcenter[1]\n",
    "            cv2.circle(img,(cx,cy),3,(255,0,0),-1)\n",
    "            #cv2.putText(img,str(c),(x1,y1),cv2.FONT_HERSHEY_PLAIN,2,(255,0,0),2)\n",
    "    cv2.imshow(\"tokyo\",img)\n",
    "    if cv2.waitKey(1) &0xFF==27: #== ord('q'): #echap sortir\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3f77c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
